{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import datetime as dt\n",
    "import torch.nn as nn\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(os.getcwd(), \"results\", \"Full_experts_check.csv\")).set_index(\"ID\")\n",
    "icps = []\n",
    "abps = []\n",
    "for row in df.iterrows():\n",
    "    row = row[1]\n",
    "    icp = row[\"icp_full\"][1:-1].replace(\",\",\"\").split(\" \")\n",
    "    icp = [float(value.strip(\"\\n\")) for value in icp if value is not \"\"]\n",
    "    icps.append(icp)\n",
    "#     print(len(icp))\n",
    "    abp = row[\"abp_full\"][1:-1].replace(\",\",\"\").split(\" \")\n",
    "    abp = [float(value.strip(\"\\n\")) for value in abp if value is not \"\"]\n",
    "#     print(len(abp))\n",
    "    abps.append(abp)\n",
    "ICP_full = torch.tensor(icps ,dtype=torch.float)\n",
    "ABP_full = torch.tensor(abps,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_prefix = \"pretraining\"\n",
    "prefixes = [ \"_Training_Artificial_AE_\", \"_Training_\", \"__\", \"_pretrained_\"]\n",
    "suffixes = [\"unfrozen\", \"pretrained\"]\n",
    "folders = os.listdir(os.path.join(os.getcwd(),\"experiments\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model_info(name, experiments):\n",
    "    for experiment in experiments:\n",
    "        if name == experiment[\"name_full\"]:\n",
    "            return {\n",
    "                \"model\": experiment[\"model\"],\n",
    "                \"o2pfcn\": experiment[\"manager\"][\"o2p_fcn\"],\n",
    "                \"input_preprocessing\": experiment[\"manager\"][\"input_preprocessing\"],\n",
    "                \"siamese\": experiment[\"dataset\"][\"siamese\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                               | 2/46 [00:00<00:02, 17.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiameseResNet\n",
      "SiameseResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▏                                                                           | 4/46 [00:00<00:03, 12.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiameseResNet\n",
      "FullyConnected\n",
      "FullyConnected_DualChannel\n",
      "LSTMFCN\n",
      "ResNet_DualChannel\n",
      "SiameseResNet"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                  | 9/46 [00:00<00:02, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN\n",
      "CNN_DualChannel\n",
      "CNN_DualChannel_Multilabel\n",
      "CNN_Multilabel\n",
      "FullyConnected_DualChannel_Multilabel\n",
      "FullyConnected_Multilabel\n",
      "LSTMFCN_DualChannel\n",
      "LSTMFCN_DualChannel_Multilabel\n",
      "LSTMFCN_Multilabel\n",
      "ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████████████████████████▏                                          | 22/46 [00:00<00:01, 17.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_DualChannel_Multilabel\n",
      "ResNet_Multilabel\n",
      "SiameseResNet_Multilabel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████████▌                     | 34/46 [00:00<00:00, 23.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN\n",
      "CNN_DualChannel\n",
      "CNN_DualChannel_Multilabel\n",
      "CNN_Multilabel\n",
      "FullyConnected\n",
      "FullyConnected_DualChannel\n",
      "FullyConnected_DualChannel_Multilabel\n",
      "FullyConnected_Multilabel\n",
      "LSTMFCN\n",
      "LSTMFCN_DualChannel\n",
      "LSTMFCN_DualChannel_Multilabel\n",
      "LSTMFCN_Multilabel\n",
      "ODE\n",
      "ODE_DualChannel\n",
      "ODE_DualChannel_Multilabel\n",
      "ODE_Multilabel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|███████████████████████████████████████████████████████████████████████▎          | 40/46 [00:05<00:01,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet\n",
      "ResNet_DualChannel\n",
      "ResNet_DualChannel_Multilabel\n",
      "ResNet_Multilabel\n",
      "SiameseNeuralODE\n",
      "SiameseNeuralODE_Multilabel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▍   | 44/46 [00:09<00:01,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiameseResNet\n",
      "SiameseResNet_Multilabel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 46/46 [00:09<00:00,  4.66it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "output_dataframe_dict = {}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "for folder in tqdm(folders):\n",
    "    experiment_name = folder\n",
    "    name = re.sub(r'\\d+-\\d+-\\d+', '', folder)\n",
    "    name = re.sub(r'\\d+', '', name)\n",
    "    if excluded_prefix not in name:\n",
    "        for prefix in prefixes:\n",
    "            name = name.replace(prefix,\"\")\n",
    "        for suffix in suffixes:\n",
    "            name = name.replace(suffix,\"\")\n",
    "        name = name.strip(\"_\")\n",
    "        model_info = find_model_info(name, experiments)\n",
    "        model_path = os.path.join(os.getcwd(), \"experiments\", experiment_name, \"model_best.pth\")\n",
    "        model = model_info[\"model\"].to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device)[\"state_dict\"])\n",
    "        model.eval()\n",
    "        \n",
    "        if model_info[\"siamese\"]:\n",
    "            model_input = [ICP_full.to(device), ABP_full.to(device)]\n",
    "        else:\n",
    "            model_input = [ICP_full.to(device)]\n",
    "            \n",
    "        if model_info[\"input_preprocessing\"] is not None:\n",
    "            input_preprocessing = model_info[\"input_preprocessing\"]\n",
    "        else:\n",
    "            input_preprocessing = lambda x: x\n",
    "        \n",
    "        if model_info[\"o2pfcn\"] is not None:\n",
    "            output_to_pred_fcn = model_info[\"o2pfcn\"]\n",
    "        else:\n",
    "            output_to_pred_fcn = lambda x: x\n",
    "        \n",
    "        model_input = input_preprocessing(model_input)\n",
    "        outputs = model(*model_input)\n",
    "        predicted = output_to_pred_fcn(outputs)\n",
    "        output_dataframe_dict[experiment_name] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataframe_dict[\"ID\"] = list(range(len(df)))\n",
    "for key in output_dataframe_dict.keys():\n",
    "    data = output_dataframe_dict[key]\n",
    "    if not isinstance(data, list):\n",
    "#         output_dataframe_dict[key] = numpy.split(data, 650)\n",
    "        if len(data.shape) > 1:\n",
    "            output_dataframe_dict[key] = [a[0] for a in np.split(data, 650)]\n",
    "df_pred = pd.DataFrame(output_dataframe_dict).set_index(\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_df = df.join(df_pred)\n",
    "scoring_df = scoring_df.rename(columns = {\"Likely type\": \"Likely\", \"Possible type\": \"Possible\"}, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Likely</th>\n",
       "      <th>Possible</th>\n",
       "      <th>abp_full</th>\n",
       "      <th>icp_full</th>\n",
       "      <th>2020-10-08_pretrained_SiameseResNet_pretrained_1</th>\n",
       "      <th>2020-10-08_pretrained_SiameseResNet_pretrained_unfrozen_1</th>\n",
       "      <th>2020-10-08__SiameseResNet_1</th>\n",
       "      <th>2020-10-11_Training_FullyConnected_1</th>\n",
       "      <th>2020-10-11_Training_FullyConnected_DualChannel_1</th>\n",
       "      <th>2020-10-11_Training_LSTMFCN_1</th>\n",
       "      <th>...</th>\n",
       "      <th>2020-10-13_Training_Artificial_AE_ODE_DualChannel_Multilabel_1</th>\n",
       "      <th>2020-10-13_Training_Artificial_AE_ODE_Multilabel_1</th>\n",
       "      <th>2020-10-13_Training_Artificial_AE_ResNet_1</th>\n",
       "      <th>2020-10-13_Training_Artificial_AE_ResNet_DualChannel_1</th>\n",
       "      <th>2020-10-13_Training_Artificial_AE_ResNet_DualChannel_Multilabel_1</th>\n",
       "      <th>2020-10-13_Training_Artificial_AE_ResNet_Multilabel_1</th>\n",
       "      <th>2020-10-13_Training_Artificial_AE_SiameseNeuralODE_1</th>\n",
       "      <th>2020-10-13_Training_Artificial_AE_SiameseNeuralODE_Multilabel_1</th>\n",
       "      <th>2020-10-13_Training_Artificial_AE_SiameseResNet_1</th>\n",
       "      <th>2020-10-13_Training_Artificial_AE_SiameseResNet_Multilabel_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[3.04814486e-02 2.18967845e-02 1.42104387e-02 ...</td>\n",
       "      <td>[5.81779680e-03 1.87093060e-03 0.00000000e+00 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.02428143 0.01584578 0.00807451 0.00233634 0...</td>\n",
       "      <td>[6.47123462e-02 5.54119309e-02 4.46266755e-02 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.59646774e-01 1.43772435e-01 1.28992707e-01 ...</td>\n",
       "      <td>[0.01877641 0.01091759 0.00506625 0.00137589 0...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.52120121e-02 4.58446053e-02 3.61205810e-02 ...</td>\n",
       "      <td>[2.67341992e-02 2.06881025e-02 1.48638903e-02 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.04620486 0.06037026 0.07319366 0.08527039 0...</td>\n",
       "      <td>[1.48506940e-02 1.06446098e-02 6.36478001e-03 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0017795, 0.0, 0.01063416, 0.01229615, 0.018...</td>\n",
       "      <td>[0.0, 0.00363864, 0.01151878, 0.02390274, 0.04...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.00449792, 0.00149089, 0.02160732, 0.03...</td>\n",
       "      <td>[0.03117772, 0.03105301, 0.03702201, 0.0494947...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.00843174, 0.00791627, 0.00437937, 0.0046104...</td>\n",
       "      <td>[0.0, 0.0012543, 0.00611003, 0.01476069, 0.027...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.00396841, 0.0, 0.00103721, 0.01148964, 0.00...</td>\n",
       "      <td>[0.0, 0.00131269, 0.00534189, 0.01230388, 0.02...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.00324341, 0.00283218, 0.002192, 0.0, 0.0025...</td>\n",
       "      <td>[0.0180761, 0.01947822, 0.02327748, 0.02974702...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Likely  Possible                                           abp_full  \\\n",
       "ID                                                                         \n",
       "0         1         1  [3.04814486e-02 2.18967845e-02 1.42104387e-02 ...   \n",
       "1         2         2  [0.02428143 0.01584578 0.00807451 0.00233634 0...   \n",
       "2         2         2  [1.59646774e-01 1.43772435e-01 1.28992707e-01 ...   \n",
       "3         1         1  [5.52120121e-02 4.58446053e-02 3.61205810e-02 ...   \n",
       "4         3         3  [0.04620486 0.06037026 0.07319366 0.08527039 0...   \n",
       "..      ...       ...                                                ...   \n",
       "645       2         2  [0.0017795, 0.0, 0.01063416, 0.01229615, 0.018...   \n",
       "646       3         3  [0.0, 0.00449792, 0.00149089, 0.02160732, 0.03...   \n",
       "647       2         4  [0.00843174, 0.00791627, 0.00437937, 0.0046104...   \n",
       "648       1         1  [0.00396841, 0.0, 0.00103721, 0.01148964, 0.00...   \n",
       "649       4         4  [0.00324341, 0.00283218, 0.002192, 0.0, 0.0025...   \n",
       "\n",
       "                                              icp_full  \\\n",
       "ID                                                       \n",
       "0    [5.81779680e-03 1.87093060e-03 0.00000000e+00 ...   \n",
       "1    [6.47123462e-02 5.54119309e-02 4.46266755e-02 ...   \n",
       "2    [0.01877641 0.01091759 0.00506625 0.00137589 0...   \n",
       "3    [2.67341992e-02 2.06881025e-02 1.48638903e-02 ...   \n",
       "4    [1.48506940e-02 1.06446098e-02 6.36478001e-03 ...   \n",
       "..                                                 ...   \n",
       "645  [0.0, 0.00363864, 0.01151878, 0.02390274, 0.04...   \n",
       "646  [0.03117772, 0.03105301, 0.03702201, 0.0494947...   \n",
       "647  [0.0, 0.0012543, 0.00611003, 0.01476069, 0.027...   \n",
       "648  [0.0, 0.00131269, 0.00534189, 0.01230388, 0.02...   \n",
       "649  [0.0180761, 0.01947822, 0.02327748, 0.02974702...   \n",
       "\n",
       "     2020-10-08_pretrained_SiameseResNet_pretrained_1  \\\n",
       "ID                                                      \n",
       "0                                                   0   \n",
       "1                                                   1   \n",
       "2                                                   1   \n",
       "3                                                   0   \n",
       "4                                                   1   \n",
       "..                                                ...   \n",
       "645                                                 1   \n",
       "646                                                 1   \n",
       "647                                                 1   \n",
       "648                                                 0   \n",
       "649                                                 1   \n",
       "\n",
       "     2020-10-08_pretrained_SiameseResNet_pretrained_unfrozen_1  \\\n",
       "ID                                                               \n",
       "0                                                    0           \n",
       "1                                                    2           \n",
       "2                                                    4           \n",
       "3                                                    0           \n",
       "4                                                    2           \n",
       "..                                                 ...           \n",
       "645                                                  1           \n",
       "646                                                  1           \n",
       "647                                                  3           \n",
       "648                                                  0           \n",
       "649                                                  3           \n",
       "\n",
       "     2020-10-08__SiameseResNet_1  2020-10-11_Training_FullyConnected_1  \\\n",
       "ID                                                                       \n",
       "0                              0                                     0   \n",
       "1                              2                                     1   \n",
       "2                              4                                     3   \n",
       "3                              0                                     0   \n",
       "4                              2                                     2   \n",
       "..                           ...                                   ...   \n",
       "645                            1                                     1   \n",
       "646                            1                                     2   \n",
       "647                            0                                     1   \n",
       "648                            0                                     0   \n",
       "649                            1                                     2   \n",
       "\n",
       "     2020-10-11_Training_FullyConnected_DualChannel_1  \\\n",
       "ID                                                      \n",
       "0                                                   0   \n",
       "1                                                   1   \n",
       "2                                                   1   \n",
       "3                                                   0   \n",
       "4                                                   1   \n",
       "..                                                ...   \n",
       "645                                                 1   \n",
       "646                                                 2   \n",
       "647                                                 1   \n",
       "648                                                 0   \n",
       "649                                                 1   \n",
       "\n",
       "     2020-10-11_Training_LSTMFCN_1  ...  \\\n",
       "ID                                  ...   \n",
       "0                                0  ...   \n",
       "1                                1  ...   \n",
       "2                                1  ...   \n",
       "3                                0  ...   \n",
       "4                                2  ...   \n",
       "..                             ...  ...   \n",
       "645                              1  ...   \n",
       "646                              1  ...   \n",
       "647                              3  ...   \n",
       "648                              1  ...   \n",
       "649                              3  ...   \n",
       "\n",
       "     2020-10-13_Training_Artificial_AE_ODE_DualChannel_Multilabel_1  \\\n",
       "ID                                                                    \n",
       "0                            [1.0, 0.0, 0.0, 0.0, 0.0]                \n",
       "1                            [0.0, 0.0, 1.0, 0.0, 0.0]                \n",
       "2                            [0.0, 0.0, 0.0, 0.0, 1.0]                \n",
       "3                            [1.0, 0.0, 0.0, 0.0, 0.0]                \n",
       "4                            [0.0, 0.0, 1.0, 0.0, 0.0]                \n",
       "..                                                 ...                \n",
       "645                          [0.0, 1.0, 0.0, 0.0, 0.0]                \n",
       "646                          [0.0, 1.0, 0.0, 0.0, 0.0]                \n",
       "647                          [0.0, 0.0, 0.0, 1.0, 0.0]                \n",
       "648                          [1.0, 0.0, 0.0, 0.0, 0.0]                \n",
       "649                          [0.0, 1.0, 0.0, 1.0, 0.0]                \n",
       "\n",
       "     2020-10-13_Training_Artificial_AE_ODE_Multilabel_1  \\\n",
       "ID                                                        \n",
       "0                            [1.0, 0.0, 0.0, 0.0, 0.0]    \n",
       "1                            [0.0, 0.0, 1.0, 0.0, 0.0]    \n",
       "2                            [0.0, 1.0, 0.0, 0.0, 0.0]    \n",
       "3                            [1.0, 0.0, 0.0, 0.0, 0.0]    \n",
       "4                            [0.0, 0.0, 1.0, 0.0, 0.0]    \n",
       "..                                                 ...    \n",
       "645                          [0.0, 1.0, 0.0, 0.0, 0.0]    \n",
       "646                          [0.0, 1.0, 0.0, 0.0, 0.0]    \n",
       "647                          [0.0, 0.0, 0.0, 0.0, 0.0]    \n",
       "648                          [0.0, 0.0, 0.0, 0.0, 1.0]    \n",
       "649                          [0.0, 1.0, 0.0, 1.0, 0.0]    \n",
       "\n",
       "     2020-10-13_Training_Artificial_AE_ResNet_1  \\\n",
       "ID                                                \n",
       "0                                             0   \n",
       "1                                             2   \n",
       "2                                             1   \n",
       "3                                             4   \n",
       "4                                             2   \n",
       "..                                          ...   \n",
       "645                                           1   \n",
       "646                                           2   \n",
       "647                                           3   \n",
       "648                                           4   \n",
       "649                                           1   \n",
       "\n",
       "     2020-10-13_Training_Artificial_AE_ResNet_DualChannel_1  \\\n",
       "ID                                                            \n",
       "0                                                    0        \n",
       "1                                                    2        \n",
       "2                                                    4        \n",
       "3                                                    4        \n",
       "4                                                    2        \n",
       "..                                                 ...        \n",
       "645                                                  1        \n",
       "646                                                  2        \n",
       "647                                                  3        \n",
       "648                                                  0        \n",
       "649                                                  1        \n",
       "\n",
       "    2020-10-13_Training_Artificial_AE_ResNet_DualChannel_Multilabel_1  \\\n",
       "ID                                                                      \n",
       "0                            [1.0, 0.0, 0.0, 0.0, 0.0]                  \n",
       "1                            [0.0, 0.0, 1.0, 0.0, 0.0]                  \n",
       "2                            [0.0, 0.0, 0.0, 0.0, 1.0]                  \n",
       "3                            [1.0, 0.0, 0.0, 0.0, 1.0]                  \n",
       "4                            [0.0, 1.0, 0.0, 0.0, 0.0]                  \n",
       "..                                                 ...                  \n",
       "645                          [0.0, 1.0, 0.0, 0.0, 0.0]                  \n",
       "646                          [0.0, 0.0, 1.0, 0.0, 0.0]                  \n",
       "647                          [0.0, 0.0, 0.0, 1.0, 0.0]                  \n",
       "648                          [1.0, 0.0, 0.0, 0.0, 0.0]                  \n",
       "649                          [0.0, 1.0, 0.0, 1.0, 0.0]                  \n",
       "\n",
       "    2020-10-13_Training_Artificial_AE_ResNet_Multilabel_1  \\\n",
       "ID                                                          \n",
       "0                            [1.0, 0.0, 0.0, 0.0, 0.0]      \n",
       "1                            [0.0, 0.0, 1.0, 0.0, 0.0]      \n",
       "2                            [0.0, 1.0, 0.0, 0.0, 0.0]      \n",
       "3                            [1.0, 0.0, 0.0, 0.0, 0.0]      \n",
       "4                            [0.0, 0.0, 0.0, 0.0, 1.0]      \n",
       "..                                                 ...      \n",
       "645                          [0.0, 1.0, 0.0, 0.0, 0.0]      \n",
       "646                          [0.0, 0.0, 1.0, 0.0, 0.0]      \n",
       "647                          [0.0, 0.0, 0.0, 1.0, 0.0]      \n",
       "648                          [0.0, 0.0, 0.0, 0.0, 0.0]      \n",
       "649                          [0.0, 1.0, 0.0, 1.0, 0.0]      \n",
       "\n",
       "    2020-10-13_Training_Artificial_AE_SiameseNeuralODE_1  \\\n",
       "ID                                                         \n",
       "0                                                    0     \n",
       "1                                                    2     \n",
       "2                                                    4     \n",
       "3                                                    0     \n",
       "4                                                    2     \n",
       "..                                                 ...     \n",
       "645                                                  1     \n",
       "646                                                  1     \n",
       "647                                                  0     \n",
       "648                                                  0     \n",
       "649                                                  1     \n",
       "\n",
       "    2020-10-13_Training_Artificial_AE_SiameseNeuralODE_Multilabel_1  \\\n",
       "ID                                                                    \n",
       "0                            [1.0, 0.0, 0.0, 0.0, 0.0]                \n",
       "1                            [0.0, 0.0, 1.0, 0.0, 0.0]                \n",
       "2                            [0.0, 0.0, 0.0, 1.0, 1.0]                \n",
       "3                            [1.0, 0.0, 0.0, 0.0, 0.0]                \n",
       "4                            [0.0, 0.0, 1.0, 0.0, 0.0]                \n",
       "..                                                 ...                \n",
       "645                          [0.0, 1.0, 0.0, 0.0, 0.0]                \n",
       "646                          [0.0, 0.0, 0.0, 0.0, 0.0]                \n",
       "647                          [0.0, 0.0, 0.0, 1.0, 0.0]                \n",
       "648                          [0.0, 1.0, 0.0, 0.0, 0.0]                \n",
       "649                          [0.0, 1.0, 0.0, 1.0, 0.0]                \n",
       "\n",
       "     2020-10-13_Training_Artificial_AE_SiameseResNet_1  \\\n",
       "ID                                                       \n",
       "0                                                    0   \n",
       "1                                                    2   \n",
       "2                                                    1   \n",
       "3                                                    0   \n",
       "4                                                    2   \n",
       "..                                                 ...   \n",
       "645                                                  1   \n",
       "646                                                  1   \n",
       "647                                                  0   \n",
       "648                                                  0   \n",
       "649                                                  1   \n",
       "\n",
       "    2020-10-13_Training_Artificial_AE_SiameseResNet_Multilabel_1  \n",
       "ID                                                                \n",
       "0                            [1.0, 0.0, 0.0, 0.0, 0.0]            \n",
       "1                            [0.0, 0.0, 1.0, 0.0, 0.0]            \n",
       "2                            [0.0, 1.0, 0.0, 0.0, 1.0]            \n",
       "3                            [1.0, 0.0, 0.0, 0.0, 0.0]            \n",
       "4                            [0.0, 0.0, 1.0, 1.0, 0.0]            \n",
       "..                                                 ...            \n",
       "645                          [0.0, 1.0, 0.0, 0.0, 0.0]            \n",
       "646                          [0.0, 0.0, 0.0, 0.0, 1.0]            \n",
       "647                          [1.0, 0.0, 0.0, 0.0, 0.0]            \n",
       "648                          [1.0, 0.0, 0.0, 0.0, 0.0]            \n",
       "649                          [0.0, 1.0, 0.0, 0.0, 0.0]            \n",
       "\n",
       "[650 rows x 49 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "rights = []\n",
    "names = scoring_df.columns[5:]\n",
    "for i in range(len(names)):\n",
    "    right = 0\n",
    "    if \"Multilabel\" in names[i]:\n",
    "        true_labels = scoring_df[\"Likely\"].values\n",
    "        possible_labels = scoring_df[\"Possible\"].values\n",
    "        predicted_labels = scoring_df[names[i]].values\n",
    "        for true, possible, predicted in zip(true_labels, possible_labels, predicted_labels):\n",
    "            if predicted[true-1] == 1 or predicted[possible-1] == 1:\n",
    "                right+=1\n",
    "    else:\n",
    "        right = len(scoring_df.loc[scoring_df[\"Likely\"] == scoring_df[names[i]] + 1])\n",
    "        right += len(scoring_df.loc[scoring_df[\"Possible\"] == scoring_df[names[i]] + 1].loc[scoring_df[\"Possible\"] != scoring_df[\"Likely\"]])\n",
    "#         right = len(scoring_df.query('`Likely` == `' + names[i] + '` + 1 or `Possible` == `' + names[i] + '` + 1'))     \n",
    "    rights.append(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-08_pretrained_SiameseResNet_pretrained_unfrozen_1 : 82.62 %\n",
      "2020-10-08__SiameseResNet_1 : 83.54 %\n",
      "2020-10-11_Training_FullyConnected_1 : 72.46 %\n",
      "2020-10-11_Training_FullyConnected_DualChannel_1 : 70.92 %\n",
      "2020-10-11_Training_LSTMFCN_1 : 80.62 %\n",
      "2020-10-11_Training_ResNet_DualChannel_1 : 81.69 %\n",
      "2020-10-11_Training_SiameseResNet_1 : 80.92 %\n",
      "2020-10-12_Training_CNN_1 : 81.54 %\n",
      "2020-10-12_Training_CNN_DualChannel_1 : 76.46 %\n",
      "2020-10-12_Training_CNN_DualChannel_Multilabel_1 : 75.69 %\n",
      "2020-10-12_Training_CNN_Multilabel_1 : 78.62 %\n",
      "2020-10-12_Training_FullyConnected_DualChannel_Multilabel_1 : 58.46 %\n",
      "2020-10-12_Training_FullyConnected_Multilabel_1 : 56.62 %\n",
      "2020-10-12_Training_LSTMFCN_DualChannel_1 : 79.54 %\n",
      "2020-10-12_Training_LSTMFCN_DualChannel_Multilabel_1 : 72.31 %\n",
      "2020-10-12_Training_LSTMFCN_Multilabel_1 : 75.08 %\n",
      "2020-10-12_Training_ResNet_1 : 86.00 %\n",
      "2020-10-12_Training_ResNet_DualChannel_Multilabel_1 : 82.92 %\n",
      "2020-10-12_Training_ResNet_Multilabel_1 : 85.69 %\n",
      "2020-10-12_Training_SiameseResNet_Multilabel_1 : 75.85 %\n",
      "2020-10-13_Training_Artificial_AE_CNN_1 : 80.62 %\n",
      "2020-10-13_Training_Artificial_AE_CNN_DualChannel_1 : 79.85 %\n",
      "2020-10-13_Training_Artificial_AE_CNN_DualChannel_Multilabel_1 : 77.08 %\n",
      "2020-10-13_Training_Artificial_AE_CNN_Multilabel_1 : 76.92 %\n",
      "2020-10-13_Training_Artificial_AE_FullyConnected_1 : 71.08 %\n",
      "2020-10-13_Training_Artificial_AE_FullyConnected_DualChannel_1 : 71.23 %\n",
      "2020-10-13_Training_Artificial_AE_FullyConnected_DualChannel_Multilabel_1 : 53.38 %\n",
      "2020-10-13_Training_Artificial_AE_FullyConnected_Multilabel_1 : 46.92 %\n",
      "2020-10-13_Training_Artificial_AE_LSTMFCN_1 : 77.23 %\n",
      "2020-10-13_Training_Artificial_AE_LSTMFCN_DualChannel_1 : 78.00 %\n",
      "2020-10-13_Training_Artificial_AE_LSTMFCN_DualChannel_Multilabel_1 : 70.31 %\n",
      "2020-10-13_Training_Artificial_AE_LSTMFCN_Multilabel_1 : 73.69 %\n",
      "2020-10-13_Training_Artificial_AE_ODE_2 : 82.62 %\n",
      "2020-10-13_Training_Artificial_AE_ODE_DualChannel_2 : 77.69 %\n",
      "2020-10-13_Training_Artificial_AE_ODE_DualChannel_Multilabel_1 : 85.54 %\n",
      "2020-10-13_Training_Artificial_AE_ODE_Multilabel_1 : 84.46 %\n",
      "2020-10-13_Training_Artificial_AE_ResNet_1 : 78.92 %\n",
      "2020-10-13_Training_Artificial_AE_ResNet_DualChannel_1 : 73.69 %\n",
      "2020-10-13_Training_Artificial_AE_ResNet_DualChannel_Multilabel_1 : 81.08 %\n",
      "2020-10-13_Training_Artificial_AE_ResNet_Multilabel_1 : 82.15 %\n",
      "2020-10-13_Training_Artificial_AE_SiameseNeuralODE_1 : 81.08 %\n",
      "2020-10-13_Training_Artificial_AE_SiameseNeuralODE_Multilabel_1 : 82.31 %\n",
      "2020-10-13_Training_Artificial_AE_SiameseResNet_1 : 81.23 %\n",
      "2020-10-13_Training_Artificial_AE_SiameseResNet_Multilabel_1 : 81.08 %\n"
     ]
    }
   ],
   "source": [
    "for name,right in zip(names, rights):\n",
    "    print(\"{} : {:2.2f} %\".format(name, right/650*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = {\"names\": names,\n",
    "          \"best_accuracy\": np.array(rights)/650*100}\n",
    "pd.DataFrame(save_df).to_csv(os.path.join(os.getcwd(), \"results\", \"final_experts_scoring_best.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86\n"
     ]
    }
   ],
   "source": [
    "print(max(rights)/650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "rights = []\n",
    "names = scoring_df.columns[5:]\n",
    "for i in range(len(names)):\n",
    "    right = 0\n",
    "    if \"Multilabel\" in names[i]:\n",
    "        true_labels = scoring_df[\"Likely\"].values\n",
    "        possible_labels = scoring_df[\"Possible\"].values\n",
    "        predicted_labels = scoring_df[names[i]].values\n",
    "        for true, possible, predicted in zip(true_labels, possible_labels, predicted_labels):\n",
    "            if predicted[true-1] == 1 and predicted[possible-1] == 1:\n",
    "                right+=1\n",
    "    else:\n",
    "        right = len(scoring_df.loc[scoring_df[\"Likely\"] == scoring_df[names[i]] + 1])\n",
    "#         right += len(scoring_df.loc[scoring_df[\"Possible\"] == scoring_df[names[i]] + 1].loc[scoring_df[\"Possible\"] != scoring_df[\"Likely\"]])\n",
    "#         right = len(scoring_df.query('`Likely` == `' + names[i] + '` + 1 or `Possible` == `' + names[i] + '` + 1'))     \n",
    "    rights.append(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-08_pretrained_SiameseResNet_pretrained_unfrozen_1 : 80.62 %\n",
      "2020-10-08__SiameseResNet_1 : 80.62 %\n",
      "2020-10-11_Training_FullyConnected_1 : 69.38 %\n",
      "2020-10-11_Training_FullyConnected_DualChannel_1 : 69.38 %\n",
      "2020-10-11_Training_LSTMFCN_1 : 77.69 %\n",
      "2020-10-11_Training_ResNet_DualChannel_1 : 78.92 %\n",
      "2020-10-11_Training_SiameseResNet_1 : 79.54 %\n",
      "2020-10-12_Training_CNN_1 : 79.38 %\n",
      "2020-10-12_Training_CNN_DualChannel_1 : 74.62 %\n",
      "2020-10-12_Training_CNN_DualChannel_Multilabel_1 : 68.46 %\n",
      "2020-10-12_Training_CNN_Multilabel_1 : 71.85 %\n",
      "2020-10-12_Training_FullyConnected_DualChannel_Multilabel_1 : 55.38 %\n",
      "2020-10-12_Training_FullyConnected_Multilabel_1 : 54.15 %\n",
      "2020-10-12_Training_LSTMFCN_DualChannel_1 : 76.31 %\n",
      "2020-10-12_Training_LSTMFCN_DualChannel_Multilabel_1 : 68.15 %\n",
      "2020-10-12_Training_LSTMFCN_Multilabel_1 : 70.46 %\n",
      "2020-10-12_Training_ResNet_1 : 81.85 %\n",
      "2020-10-12_Training_ResNet_DualChannel_Multilabel_1 : 76.77 %\n",
      "2020-10-12_Training_ResNet_Multilabel_1 : 80.00 %\n",
      "2020-10-12_Training_SiameseResNet_Multilabel_1 : 70.46 %\n",
      "2020-10-13_Training_Artificial_AE_CNN_1 : 77.54 %\n",
      "2020-10-13_Training_Artificial_AE_CNN_DualChannel_1 : 77.69 %\n",
      "2020-10-13_Training_Artificial_AE_CNN_DualChannel_Multilabel_1 : 70.77 %\n",
      "2020-10-13_Training_Artificial_AE_CNN_Multilabel_1 : 71.54 %\n",
      "2020-10-13_Training_Artificial_AE_FullyConnected_1 : 68.92 %\n",
      "2020-10-13_Training_Artificial_AE_FullyConnected_DualChannel_1 : 69.54 %\n",
      "2020-10-13_Training_Artificial_AE_FullyConnected_DualChannel_Multilabel_1 : 49.85 %\n",
      "2020-10-13_Training_Artificial_AE_FullyConnected_Multilabel_1 : 44.46 %\n",
      "2020-10-13_Training_Artificial_AE_LSTMFCN_1 : 74.31 %\n",
      "2020-10-13_Training_Artificial_AE_LSTMFCN_DualChannel_1 : 73.85 %\n",
      "2020-10-13_Training_Artificial_AE_LSTMFCN_DualChannel_Multilabel_1 : 65.23 %\n",
      "2020-10-13_Training_Artificial_AE_LSTMFCN_Multilabel_1 : 68.92 %\n",
      "2020-10-13_Training_Artificial_AE_ODE_2 : 79.38 %\n",
      "2020-10-13_Training_Artificial_AE_ODE_DualChannel_2 : 74.62 %\n",
      "2020-10-13_Training_Artificial_AE_ODE_DualChannel_Multilabel_1 : 78.15 %\n",
      "2020-10-13_Training_Artificial_AE_ODE_Multilabel_1 : 77.69 %\n",
      "2020-10-13_Training_Artificial_AE_ResNet_1 : 74.62 %\n",
      "2020-10-13_Training_Artificial_AE_ResNet_DualChannel_1 : 70.92 %\n",
      "2020-10-13_Training_Artificial_AE_ResNet_DualChannel_Multilabel_1 : 74.46 %\n",
      "2020-10-13_Training_Artificial_AE_ResNet_Multilabel_1 : 75.69 %\n",
      "2020-10-13_Training_Artificial_AE_SiameseNeuralODE_1 : 78.77 %\n",
      "2020-10-13_Training_Artificial_AE_SiameseNeuralODE_Multilabel_1 : 76.00 %\n",
      "2020-10-13_Training_Artificial_AE_SiameseResNet_1 : 77.85 %\n",
      "2020-10-13_Training_Artificial_AE_SiameseResNet_Multilabel_1 : 75.08 %\n"
     ]
    }
   ],
   "source": [
    "for name,right in zip(names, rights):\n",
    "    print(\"{} : {:2.2f} %\".format(name, right/650*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = {\"names\": names,\n",
    "          \"strict_accuracy\": np.array(rights)/650*100}\n",
    "pd.DataFrame(save_df).to_csv(os.path.join(os.getcwd(), \"results\", \"final_experts_scoring_strict.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pickle\n",
    "import datetime as dt\n",
    "from experiment_manager import Manager\n",
    "from models.CNNmodel import CNN\n",
    "from models.FCmodel import FCmodel  \n",
    "from models.RNNmodel import LSTMFCN\n",
    "from models.SiameseModels import SiameseNeuralODE, SiameseResNet\n",
    "from models.ResnetODEmodels import ODE, ResNet\n",
    "from utils import resampling_dataset_loader, Memory_efficient_loader, learning_rate_with_decay\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score\n",
    "from metrics import best_accuracy_ml\n",
    "\n",
    "length = 100\n",
    "test_dataset = None\n",
    "train_dateset = None\n",
    "\n",
    "experiments = [\n",
    "    {\n",
    "        \"model\": SiameseResNet(5, ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"SiameseResNet\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": None\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"model\": FCmodel(180, 5, ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"FullyConnected\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": None\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": False,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"model\": LSTMFCN(180, 5, ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"LSTMFCN\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": None\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": False,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": ResNet(5),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"ResNet\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": lambda x: [a.unsqueeze(1) for a in x]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": False,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": CNN(5),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"CNN\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": lambda x: [a.unsqueeze(1) for a in x]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": False,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": FCmodel(360, 5, ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"FullyConnected_DualChannel\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": lambda x: [torch.cat(x, dim=1)]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"model\": LSTMFCN(180, 5, channels=[2, 32, 64, 32], ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"LSTMFCN_DualChannel\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": lambda x: [torch.stack(x, dim=1)]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": ResNet(5, in_channels=2),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"ResNet_DualChannel\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": lambda x: [torch.stack(x, dim=1)]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": CNN(5, channels=[2, 32, 64, 64]),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"CNN_DualChannel\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": lambda x: [torch.stack(x, dim=1)]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": SiameseResNet(5, ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"SiameseResNet_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": None\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"model\": FCmodel(180, 5, ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"FullyConnected_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": None\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": False,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"model\": LSTMFCN(180, 5, ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"LSTMFCN_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": None\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": False,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": ResNet(5),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"ResNet_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": lambda x: [a.unsqueeze(1) for a in x]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": False,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": CNN(5),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"CNN_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": lambda x: [a.unsqueeze(1) for a in x]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": False,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": FCmodel(360, 5, ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"FullyConnected_DualChannel_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": lambda x: [torch.cat(x, dim=1)]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"model\": LSTMFCN(180, 5, channels=[2, 32, 64, 32], ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"LSTMFCN_DualChannel_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": lambda x: [torch.stack(x, dim=1)]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": ResNet(5, in_channels=2),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"ResNet_DualChannel_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": lambda x: [torch.stack(x, dim=1)]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": CNN(5, channels=[2, 32, 64, 64]),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"CNN_DualChannel_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": False,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": lambda x: [torch.stack(x, dim=1)]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": SiameseNeuralODE(5, ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"SiameseNeuralODE\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": True,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": None\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": False,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": SiameseNeuralODE(5, ae=False),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"SiameseNeuralODE_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": True,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": None\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": False,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": ODE(5, in_channels=2),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"ODE_DualChannel_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": True,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": lambda x: [torch.stack(x, dim=1)]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": False,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": ODE(5),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"ODE_Multilabel\",\n",
    "        \"criterion\": nn.BCELoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"macro\"),\n",
    "                \"Jaccard\": lambda labels, preds: jaccard_score(labels, preds, average=\"macro\"),\n",
    "                \"Best_accuracy\": best_accuracy_ml\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.where(torch.sigmoid(x.cpu().detach()).numpy() >= 0.5, np.ones(x.shape), np.zeros(x.shape)),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": True,\n",
    "            \"loss_preprocessing\": lambda x: torch.sigmoid(x),\n",
    "            \"leading_metric\": \"F1_Score\",\n",
    "            \"input_preprocessing\": lambda x: [a.unsqueeze(1) for a in x]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": False,\n",
    "            \"multilabel\": True,\n",
    "            \"include_artificial_ae\": False,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": ODE(5),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"ODE\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": True,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": lambda x: [a.unsqueeze(1) for a in x]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": False,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"model\": ODE(5, in_channels=2),\n",
    "        \"pretrained\": False,\n",
    "        \"pretraining_path\": None,\n",
    "        \"name_full\": \"ODE_DualChannel\",\n",
    "        \"criterion\": nn.CrossEntropyLoss(),\n",
    "        \"optimizer\": lambda x: torch.optim.SGD(x, lr=0.01, momentum=0.95, nesterov=True),\n",
    "        \"scheduler\": learning_rate_with_decay(0.01, 256, 256, length, boundary_epochs=[33, 66], decay_rates=[1, 0.1, 0.01]),\n",
    "        \"manager\": {\n",
    "            \"pretraining\": False,\n",
    "            \"metrics\": {\n",
    "                \"Accuracy\": accuracy_score,\n",
    "                \"F1_Score\": lambda labels, preds: f1_score(labels, preds, average=\"weighted\")\n",
    "            },\n",
    "            \"o2p_fcn\": lambda x: np.argmax(x.cpu().detach().numpy(), axis=1),\n",
    "            \"test_dataset\": test_dataset,\n",
    "            \"loader_size\": 256,\n",
    "            \"normalize\": True,\n",
    "            \"nfe_logging\": True,\n",
    "            \"loss_preprocessing\": None,\n",
    "            \"leading_metric\": \"Accuracy\",\n",
    "            \"input_preprocessing\": lambda x: [torch.stack(x, dim=1)]\n",
    "        },\n",
    "        \"dataset\": {\n",
    "            \"siamese\": True,\n",
    "            \"multilabel\": False,\n",
    "            \"include_artificial_ae\": True,\n",
    "            \"transforms\": None\n",
    "        }\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
