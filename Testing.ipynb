{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e9adbb999f4e75adbc17d67ef5408b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='test_filename_id', max=1850), Dropdown(description='expe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "path = os.path.join(os.getcwd())\n",
    "dataset_path = os.path.join(path, \"datasets\", \"full_corrected_dataset\", \"test\")\n",
    "experiments_path = os.path.join(path, \"experiments\")\n",
    "\n",
    "filenames = [f for f in listdir(dataset_path) if isfile(join(dataset_path, f))]\n",
    "experiments = [f for f in listdir(experiments_path) if not isfile(join(experiments_path, f))]\n",
    "models = [\"best\", \"final\"]\n",
    "\n",
    "@interact(test_filename_id=(0,len(filenames)-1,1), experiment=experiments, bestOrFinal=models)\n",
    "def test_model(test_filename_id=1,experiment=1,bestOrFinal=1):\n",
    "    filename = filenames[test_filename_id]\n",
    "    experiment_name = experiment\n",
    "    model = bestOrFinal\n",
    "    model_path = os.path.join(experiments_path, experiment_name, \"model_weights\", \"model_\" + model + \".pth\")\n",
    "\n",
    "    mapping_path = os.path.join(path, \"datasets\", \"full_corrected_dataset_to_RAW_mapping.csv\")\n",
    "    file_path = os.path.join(dataset_path, filename)\n",
    "\n",
    "    mapping = pd.read_csv(mapping_path, sep=\";\")\n",
    "    data_csv = pd.read_csv(file_path)\n",
    "    \n",
    "    original_filename = mapping.loc[mapping['new_id'] == filename].values[:, 2][0]\n",
    "    tensors = []\n",
    "    padding_minimum = torch.zeros(180)\n",
    "    \n",
    "    if \"4cls\" in experiment_name:\n",
    "        names = [\"T1\", \"T2\", \"T3\", \"T4\"]\n",
    "    else:\n",
    "        names = [\"T1\", \"T2\", \"T3\", \"T4\", \"A+E\"]\n",
    "\n",
    "    data = data_csv.iloc[:, 1:].values[:, 0]\n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    input_tensor = torch.tensor(data, dtype=torch.double)\n",
    "\n",
    "    tensors.append(input_tensor)\n",
    "    tensors.append(padding_minimum)\n",
    "    tensors = torch.nn.utils.rnn.pad_sequence(tensors, batch_first=True)\n",
    "    tensors = tensors[:-1]\n",
    "\n",
    "    model = torch.load(model_path,map_location=torch.device('cpu'))\n",
    "    model.eval()\n",
    "    outputs = model(tensors)\n",
    "    softmax_outputs = F.softmax(outputs, dim=1).tolist()[0]\n",
    "    \n",
    "    print(\"Filename: {}\\n\".format(str(filename)),\n",
    "         \"Original file location: {}\\n\".format(str(original_filename)),\n",
    "         \"Model: {}\\n{}\\n\".format(str(experiment_name), model),\n",
    "         \"Original class: {}\\n\".format(filename.split(\"_\")[0]),\n",
    "         \"Predicted class: {}\\n\".format(names[np.argmax(softmax_outputs, axis=0)]),\n",
    "         \"Predicted probability: {}\\n\".format(np.max(softmax_outputs)))\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(211)\n",
    "    plt.plot(data_csv.iloc[:, 0:].values[:, 0],data_csv.iloc[:, 1:].values[:, 0])\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.bar(names, softmax_outputs)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "mapping_1 = pd.read_csv(os.path.join(os.getcwd(), \"datasets\", \"RAW_extended_dataset_to_full_extended_dataset_mapping.csv\"))\n",
    "test = pd.read_csv(os.path.join(os.getcwd(), \"datasets\", \"test_corrections.csv\"))\n",
    "train = pd.read_csv(os.path.join(os.getcwd(), \"datasets\", \"train_corrections.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for row in train.iterrows():\n",
    "    row = row[1]\n",
    "    name = row[\"PULSE\"].strip(\".csv\")\n",
    "    queried = mapping_1.query(\"new_id == \\'\"+name+\".csv\\'\")\n",
    "    if len(queried) == 0:\n",
    "        print(\"Not found \"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>new_id</th>\n",
       "      <th>RAW_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AE_0.csv</td>\n",
       "      <td>C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AE_1.csv</td>\n",
       "      <td>C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AE_2.csv</td>\n",
       "      <td>C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>T1_3.csv</td>\n",
       "      <td>C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>T1_4.csv</td>\n",
       "      <td>C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24268</th>\n",
       "      <td>24268</td>\n",
       "      <td>T4_24268.csv</td>\n",
       "      <td>C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24269</th>\n",
       "      <td>24269</td>\n",
       "      <td>T4_24269.csv</td>\n",
       "      <td>C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24270</th>\n",
       "      <td>24270</td>\n",
       "      <td>T4_24270.csv</td>\n",
       "      <td>C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24271</th>\n",
       "      <td>24271</td>\n",
       "      <td>T4_24271.csv</td>\n",
       "      <td>C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24272</th>\n",
       "      <td>24272</td>\n",
       "      <td>T4_24272.csv</td>\n",
       "      <td>C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24273 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        new_id  \\\n",
       "0               0      AE_0.csv   \n",
       "1               1      AE_1.csv   \n",
       "2               2      AE_2.csv   \n",
       "3               3      T1_3.csv   \n",
       "4               4      T1_4.csv   \n",
       "...           ...           ...   \n",
       "24268       24268  T4_24268.csv   \n",
       "24269       24269  T4_24269.csv   \n",
       "24270       24270  T4_24270.csv   \n",
       "24271       24271  T4_24271.csv   \n",
       "24272       24272  T4_24272.csv   \n",
       "\n",
       "                                                RAW_path  \n",
       "0      C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...  \n",
       "1      C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...  \n",
       "2      C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...  \n",
       "3      C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...  \n",
       "4      C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...  \n",
       "...                                                  ...  \n",
       "24268  C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...  \n",
       "24269  C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...  \n",
       "24270  C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...  \n",
       "24271  C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...  \n",
       "24272  C:\\Users\\cmata\\Desktop\\ICPPRoject\\icp_17.03\\IC...  \n",
       "\n",
       "[24273 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_ode = pd.read_csv(os.path.join(os.getcwd(), \"datasets\", \"RAW_extended_dataset_to_full_extended_dataset_mapping.csv\"))\n",
    "mapping_siam = pd.read_csv(os.path.join(os.getcwd(), \"datasets\", \"RAW_siamese_dataset_to_full_siamese_dataset_mapping.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ode_dict = {}\n",
    "siam_dict = {}\n",
    "final_dict = {}\n",
    "for row in mapping_ode.iterrows():\n",
    "    row = row[1]\n",
    "    ID = row[\"new_id\"]\n",
    "    original_name = row[\"RAW_path\"].split('\\\\')[-1]\n",
    "    ode_dict[original_name] = ID\n",
    "for row in mapping_siam.iterrows():\n",
    "    row = row[1]\n",
    "    ID = row[\"new_id\"]\n",
    "    original_name = row[\"RAW_path\"].split('\\\\')[-1]\n",
    "    siam_dict[original_name] = ID\n",
    "    final_dict[ID] = ode_dict[original_name]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mapping={\n",
    "    \"siam_name\": [],\n",
    "    \"extended_name\": []\n",
    "}\n",
    "for entry in final_dict:\n",
    "    out_mapping[\"siam_name\"].append(entry)\n",
    "    out_mapping[\"extended_name\"].append(final_dict[entry])\n",
    "df = pd.DataFrame(out_mapping)\n",
    "df.to_csv(os.path.join(os.getcwd(), \"datasets\", \"full_siamese_dataset_to_full_extended_dataset_mapping.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>siam_name</th>\n",
       "      <th>extended_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE_0.csv</td>\n",
       "      <td>AE_17307.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2_1.csv</td>\n",
       "      <td>T2_17308.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T2_2.csv</td>\n",
       "      <td>T2_17309.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T2_3.csv</td>\n",
       "      <td>T2_17310.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T2_4.csv</td>\n",
       "      <td>T2_17311.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21385</th>\n",
       "      <td>T4_21385.csv</td>\n",
       "      <td>T4_24189.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21386</th>\n",
       "      <td>T4_21386.csv</td>\n",
       "      <td>T4_24190.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21387</th>\n",
       "      <td>T4_21387.csv</td>\n",
       "      <td>T4_24191.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21388</th>\n",
       "      <td>T4_21388.csv</td>\n",
       "      <td>T4_24192.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21389</th>\n",
       "      <td>T4_21389.csv</td>\n",
       "      <td>T4_24193.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21390 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          siam_name extended_name\n",
       "0          AE_0.csv  AE_17307.csv\n",
       "1          T2_1.csv  T2_17308.csv\n",
       "2          T2_2.csv  T2_17309.csv\n",
       "3          T2_3.csv  T2_17310.csv\n",
       "4          T2_4.csv  T2_17311.csv\n",
       "...             ...           ...\n",
       "21385  T4_21385.csv  T4_24189.csv\n",
       "21386  T4_21386.csv  T4_24190.csv\n",
       "21387  T4_21387.csv  T4_24191.csv\n",
       "21388  T4_21388.csv  T4_24192.csv\n",
       "21389  T4_21389.csv  T4_24193.csv\n",
       "\n",
       "[21390 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
